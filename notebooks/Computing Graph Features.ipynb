{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8b7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de0d19",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Reading CSV file into a dictionary instead of using pd.read_csv() because indexing in pandas is very slow compared to standard Python dictionaries and I've found that it's much faster to compute segment features (length, duration, and speed) on dictionary due to inexpensive dictionary lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387d9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "def parse_bool(bool_str):\n",
    "    if bool_str == \"false\":\n",
    "        return False\n",
    "    elif bool_str == \"true\":\n",
    "        return True\n",
    "\n",
    "with open(\"../data/data_scientist_case.csv\", mode='r', encoding='utf-8-sig') as f:\n",
    "    columns = f.readline().strip().replace(\"\\\"\", \"\").split(\",\")\n",
    "\n",
    "    for line in f:\n",
    "        values = list(csv.reader([line], delimiter=',', quotechar='\"'))[0]\n",
    "\n",
    "        # driver_id\n",
    "        d[values[1]][values[2]][columns[0]] = values[0]\n",
    "\n",
    "        # segment_datetime\n",
    "        d[values[1]][values[2]][columns[3]] = datetime.strptime(values[3], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # published_date\n",
    "        d[values[1]][values[2]][columns[4]] = datetime.strptime(values[4], '%Y-%m-%d %H:%M:%S') # segment_datetime\n",
    "\n",
    "        # signup_date\n",
    "        d[values[1]][values[2]][columns[5]] = datetime.strptime(values[5], '%Y-%m-%d %H:%M:%S') # segment_datetime\n",
    "\n",
    "        # fixed_signup_country\n",
    "        d[values[1]][values[2]][columns[6]] = values[6].strip()\n",
    "\n",
    "        # is_main_segment\n",
    "        d[values[1]][values[2]][columns[7]] = parse_bool(values[7])\n",
    "\n",
    "        # unit_seat_price_eur\n",
    "        d[values[1]][values[2]][columns[8]] = float(values[8].replace(\",\", \"\"))\n",
    "\n",
    "        # seat_offered_count\n",
    "        d[values[1]][values[2]][columns[9]] = int(values[9])\n",
    "\n",
    "        #seat_left_count\n",
    "        d[values[1]][values[2]][columns[10]] = int(values[10])\n",
    "\n",
    "        # confirmed_seat_count\n",
    "        d[values[1]][values[2]][columns[11]] = int(values[11])\n",
    "\n",
    "        # segment_distance_km\n",
    "        d[values[1]][values[2]][columns[12]] = float(values[12].replace(\",\", \"\"))\n",
    "\n",
    "        # from (lat, lon)\n",
    "        d[values[1]][values[2]][\"from\"] = (float(values[13]), float(values[14]))\n",
    "\n",
    "        # to (lat, lon)\n",
    "        d[values[1]][values[2]][\"to\"] = (float(values[15]), float(values[16]))\n",
    "\n",
    "        # is_comfort\n",
    "        d[values[1]][values[2]][columns[17]] = parse_bool(values[17])\n",
    "\n",
    "        # is_auto_accept_mode\n",
    "        d[values[1]][values[2]][columns[18]] = parse_bool(values[18])\n",
    "\n",
    "        # publication_site_id\n",
    "        d[values[1]][values[2]][columns[19]] = values[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bf8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to represent a graph\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.graph = defaultdict(set) #dictionary containing adjacency List\n",
    "        self.vertices = set()\n",
    " \n",
    "    # function to add an edge to graph\n",
    "    def addEdge(self, u, v):\n",
    "        self.vertices.add(u)\n",
    "        self.vertices.add(v)\n",
    "        self.graph[u].add(v)\n",
    " \n",
    "    # A recursive function used by topologicalSort\n",
    "    def topologicalSortUtil(self, v, visited, stack):\n",
    " \n",
    "        # Mark the current node as visited.\n",
    "        visited[v] = True\n",
    " \n",
    "        # Recur for all the vertices adjacent to this vertex\n",
    "        for i in self.graph[v]:\n",
    "            if visited[i] == False:\n",
    "                self.topologicalSortUtil(i, visited, stack)\n",
    " \n",
    "        # Push current vertex to stack which stores result\n",
    "        stack.insert(0, v)\n",
    " \n",
    "    # The function to do Topological Sort. It uses recursive\n",
    "    # topologicalSortUtil()\n",
    "    def topologicalSort(self):\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = defaultdict(bool)\n",
    "        stack =[]\n",
    " \n",
    "        # Call the recursive helper function to store Topological\n",
    "        # Sort starting from all vertices one by one\n",
    "        for v in self.vertices:\n",
    "            if visited[v] == False:\n",
    "                self.topologicalSortUtil(v, visited, stack)\n",
    " \n",
    "        # Return contents of stack\n",
    "        return stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4824538",
   "metadata": {},
   "source": [
    "### Extracting graph features\n",
    "\n",
    "Below is code for extracting segment length (number of subsegments), segment duration (if possible), and segment speed (if possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7faa7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_segment_features(trip_id):\n",
    "    point_pair_to_segment = {}\n",
    "\n",
    "    points = set([d[trip_id][x][\"from\"] for x in d[trip_id].keys()])\n",
    "    points = points.union([d[trip_id][x][\"to\"] for x in d[trip_id].keys()])\n",
    "\n",
    "    g = Graph()\n",
    "    for segment_id in d[trip_id].keys():\n",
    "        g.addEdge(d[trip_id][segment_id][\"from\"], d[trip_id][segment_id][\"to\"])\n",
    "        point_pair_to_segment[\n",
    "            d[trip_id][segment_id][\"from\"] + d[trip_id][segment_id][\"to\"]\n",
    "        ] = segment_id\n",
    "\n",
    "    # Verify that graph is correct\n",
    "    # every node must be connected to all the nodes that come after it in sorted topological order\n",
    "    sorted_locations = g.topologicalSort()\n",
    "    for i in range(len(sorted_locations)):\n",
    "        for j in range(i + 1, len(sorted_locations)):\n",
    "            if sorted_locations[j] not in g.graph[sorted_locations[i]]:\n",
    "                for segment in d[trip_id].keys():\n",
    "                    d[trip_id][segment][\"length\"] = None\n",
    "                    d[trip_id][segment][\"duration\"] = None\n",
    "                    d[trip_id][segment][\"speed\"] = None\n",
    "                return\n",
    "\n",
    "    seg_to_seg = defaultdict(list)\n",
    "    for i in range(len(sorted_locations)):\n",
    "        cur_segments = []\n",
    "        for j in range(i + 1, len(sorted_locations)):\n",
    "            cur_segments.append(\n",
    "                point_pair_to_segment[(sorted_locations[j - 1] + sorted_locations[j])]\n",
    "            )\n",
    "            seg_to_seg[\n",
    "                point_pair_to_segment[(sorted_locations[i] + sorted_locations[j])]\n",
    "            ] = [x for x in cur_segments]\n",
    "\n",
    "    sorted_core_segments = []\n",
    "    for i in range(len(sorted_locations) - 1):\n",
    "        sorted_core_segments.append(\n",
    "            point_pair_to_segment[sorted_locations[i] + sorted_locations[i + 1]]\n",
    "        )\n",
    "\n",
    "    segment_durations = {}\n",
    "    for i in range(len(sorted_core_segments) - 1):\n",
    "        s1 = sorted_core_segments[i]\n",
    "        s2 = sorted_core_segments[i + 1]\n",
    "        duration = (\n",
    "            d[trip_id][s2][\"segment_datetime\"] - d[trip_id][s1][\"segment_datetime\"]\n",
    "        )\n",
    "        duration = duration.seconds / 3600\n",
    "        if duration != 0:\n",
    "            segment_durations[s1] = duration\n",
    "        else:\n",
    "            segment_durations[s1] = None\n",
    "\n",
    "    for segment in d[trip_id].keys():\n",
    "        if segment not in segment_durations:\n",
    "            subsegs = seg_to_seg[segment]\n",
    "            s = 0\n",
    "            all_known = True\n",
    "            for seg in subsegs:\n",
    "                if seg in segment_durations and segment_durations[seg] != None:\n",
    "                    s += segment_durations[seg]\n",
    "                else:\n",
    "                    all_known = False\n",
    "                    break\n",
    "            if all_known:\n",
    "                segment_durations[segment] = s\n",
    "\n",
    "    segment_speeds = {}\n",
    "    for segment in segment_durations:\n",
    "        duration = segment_durations[segment]\n",
    "        if duration != None and duration > 0:\n",
    "            segment_speeds[segment] = (\n",
    "                d[trip_id][segment][\"segment_distance_km\"] / segment_durations[segment]\n",
    "            )\n",
    "        else:\n",
    "            segment_speeds[segment] = None\n",
    "\n",
    "    segment_lengths = {}\n",
    "    for segment in seg_to_seg:\n",
    "        segment_lengths[segment] = len(seg_to_seg[segment])\n",
    "\n",
    "    for segment in segment_lengths:\n",
    "        d[trip_id][segment][\"length\"] = segment_lengths[segment]\n",
    "        d[trip_id][segment][\"duration\"] = segment_durations.get(segment)\n",
    "        d[trip_id][segment][\"speed\"] = segment_speeds.get(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464f60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 704411/704411 [00:21<00:00, 32548.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for trip_id in tqdm(d.keys()):\n",
    "    compute_segment_features(trip_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1560772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "    (i, j): d[i][j] for i in d.keys() for j in d[i].keys()\n",
    "}, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fbca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = [\"trip_id\", \"segment_id\"]\n",
    "df.to_csv(\"../data/with_segment_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf96ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
